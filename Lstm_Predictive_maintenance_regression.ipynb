{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lstm_Predictive_maintance_regression.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafaBozkurt84/predictive-maintanance-LSTM/blob/master/Lstm_Predictive_maintenance_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSRyvfdIdvNM"
      },
      "source": [
        "# RegressionÂ¶\n",
        "How many  hours an in-service engine will last before it fails?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci0h-p7Xuc8p",
        "outputId": "6620853d-98c3-4a93-e3d7-69b35f237a9e"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers.core import Activation\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Setting seed for reproducibility\n",
        "np.random.seed(1234)  \n",
        "PYTHONHASHSEED = 0\n",
        "\n",
        "\n",
        "##################################\n",
        "# Data Ingestion\n",
        "##################################\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbbT2od9AYJ1"
      },
      "source": [
        "#df = pd.read_excel(\"/content/drive/MyDrive/Datasets/predictive maintance /AnalizDataPM.xlsx\",engine='openpyxl')\n",
        "#df[\"Time\"]= [str(i).replace(\"2020-02-02\",\"2/2/2020\").replace(\"2020-01-02\",\"2/1/2020\") for i in df[\"Time\"]]\n",
        "#df['Time'] = pd.to_datetime(df['Time']) \n",
        "#df['Time']=[str(i).split(\":\")[0] for i in df[\"Time\"]]\n",
        "#df['Time'] = pd.to_datetime(df['Time'],format=\"%Y-%m-%d %H\") #%Y-%m-%d %H:%M:%S\n",
        "#df=df.groupby(\"Time\").mean()\n",
        "#df.reset_index(inplace=True)\n",
        "#df.to_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /DataAnaliz.csv\")\n",
        "#df.head()\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZnZo8krrVhl"
      },
      "source": [
        "#df=pd.read_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /DataAnaliz.csv\")\n",
        "#df['Time'] = pd.to_datetime(df['Time'],format=\"%Y-%m-%d %H\") #%Y-%m-%d %H:%M:%S\n",
        "#df=df.iloc[:,1:]\n",
        "#df"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUPkKk9BiY4s"
      },
      "source": [
        "\n",
        "df =pd.read_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /31_hidrolikmotoru_analiz.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p47zUyT3iaND"
      },
      "source": [
        "df.drop([\"name\",\"partno\",\"balancerbasinci\",\"spm\",\"xkurt\"],axis=1,inplace=True)\n",
        "df.columns=['Time', 'vibx', 'vibz', 'temp', 'zacc', 'zfreq', 'crest']\n",
        "df[\"Time\"]= [str(i).replace(\"2020-02-02\",\"2/2/2020\").replace(\"2020-01-02\",\"2/1/2020\") for i in df[\"Time\"]]\n",
        "\n",
        "df['Time'] = pd.to_datetime(df['Time']) \n",
        "df['Time']=[str(i).split(\":\")[0] for i in df[\"Time\"]]\n",
        "df['Time'] = pd.to_datetime(df['Time'],format=\"%Y-%m-%d %H\") #%Y-%m-%d %H:%M:%S\n",
        "\n",
        "df=df.groupby(\"Time\").mean()\n",
        "df.reset_index(inplace=True)\n",
        "df.to_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /DataAnaliz.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFpBow4MifBb"
      },
      "source": [
        "data=df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIKlR5yGih2Y"
      },
      "source": [
        "\n",
        "ariza_tarihleri=[\"2020-01-27 14:00:00\",\"2020-09-11 14:00:00\",\"2020-10-06 18:00:00\",\"2020-10-10 08:00:00\",\"2020-10-13 04:00:00\",\"2020-10-18 00:00:00\",\"2020-10-30 09:00:00\",\"2020-11-02 05:00:00\"]\n",
        "ariza_index = []\n",
        "for i in ariza_tarihleri:\n",
        "  ariza_index.append(df[df[\"Time\"]==i].index[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpz_-z_VoiPg"
      },
      "source": [
        "df['Hour'] = df['Time'].apply(lambda time: time.hour)\n",
        "df['Month'] = df['Time'].apply(lambda time: time.month)\n",
        "df['Day of Week'] = df['Time'].apply(lambda time: time.dayofweek)\n",
        "df['Year'] = df['Time'].apply(lambda t: t.year)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8_9a8N3q6fc"
      },
      "source": [
        "df=pd.get_dummies(df,columns=['Hour','Month','Day of Week','Year'],drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qLXRImXrCvT"
      },
      "source": [
        "for col in df.columns[1:7]:\n",
        "  for i in range(1,4):\n",
        "      df['lag_'+str(i)+col] = df[col].shift(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c2m1fLTYiAi"
      },
      "source": [
        "for col in df.columns[1:7]:\n",
        "  df[col+'expanding_mean'] = df[col].expanding(24*7).mean()\n",
        "  df[col+'expanding_std'] = df[col].expanding(24*7).std()\n",
        "df.dropna(axis=0,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-1gScWArIzt"
      },
      "source": [
        "df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMTzySFU6hhV"
      },
      "source": [
        "ariza_tarihleri=[\"2020-01-27 14:00:00\",\"2020-09-11 14:00:00\",\"2020-10-06 18:00:00\",\"2020-10-10 08:00:00\",\"2020-10-13 04:00:00\",\"2020-10-18 00:00:00\",\"2020-10-30 09:00:00\",\"2020-11-02 05:00:00\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poEK4WwK8NZG"
      },
      "source": [
        "df[\"rul\"]=[np.nan for i in df.index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXsUpjz47BRi"
      },
      "source": [
        "len(rul)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPrfqgpJ2ZLp"
      },
      "source": [
        "onceki_ariza = 0\n",
        "for i in range(len(ariza_tarihleri)):\n",
        "  ariza=ariza_tarihleri[i]\n",
        "  if onceki_ariza!=0:\n",
        "    onceki_ariza = ariza_tarihleri[i-1]\n",
        "  else:\n",
        "    onceki_ariza =\"2020-01-01 04:00:00\"\n",
        "  rul=[i for i in range(len(df.loc[df[df[\"Time\"]==onceki_ariza].index[0]:df[df[\"Time\"]==ariza].index[0]-1,\"rul\"].tolist()))]\n",
        "  rul.reverse()\n",
        "  df.loc[df[df[\"Time\"]==onceki_ariza].index[0]:df[df[\"Time\"]==ariza].index[0]-1,\"rul\"]= rul"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fCVo6e73qFJ"
      },
      "source": [
        "df[\"rul\"].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFgNtzsaqV6W"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ya73bv2orPt"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsZ4_YTZx8uT"
      },
      "source": [
        "ariza_tarihleri"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu6oqHnf7_K8"
      },
      "source": [
        "train_df=df[df[\"Time\"]<=\"2020-10-18 00:00:00\"]\n",
        "test_df = df[df[\"Time\"]>\"2020-10-18 00:00:00\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEt_tT2bnOBN"
      },
      "source": [
        "# MinMax normalization (from 0 to 1)\n",
        "\n",
        "cols_normalize = df.columns[1:-1]\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
        "                             columns=cols_normalize, \n",
        "                             index=train_df.index)\n",
        "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "train_df = join_df.reindex(columns = train_df.columns)\n",
        "\n",
        "#Test\n",
        "\n",
        "\n",
        "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
        "                            columns=cols_normalize, \n",
        "                            index=test_df.index)\n",
        "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
        "test_df = test_join_df.reindex(columns = test_df.columns)\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BwG1niy7tCz"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dy18bBgqpWn"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1yzRNf88_DY"
      },
      "source": [
        "# pick  window size \n",
        "sequence_length = 24\n",
        "\n",
        "# function to reshape features into (samples, time steps, features)\n",
        "\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    # for one id I put all the rows in a single matrix\n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # Iterate over two lists in parallel.\n",
        "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
        "    # so zip iterate over two following list of numbers (0,112),(50,192)\n",
        "    # 0 50 -> from row 0 to row 50\n",
        "    # 1 51 -> from row 1 to row 51\n",
        "    # 2 52 -> from row 2 to row 52\n",
        "    # ...\n",
        "    # 111 191 -> from row 111 to 191\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "        \n",
        "# pick the feature columns \n",
        "sequence_cols=train_df.columns.difference([\"rul\",\"Time\"])\n",
        "\n",
        "# generator for the sequences\n",
        "#seq_gen=(list(gen_sequence(train_df[train_df.index==id], sequence_length, sequence_cols))  for id in train_df.index)\n",
        "seq_gen = list(list(gen_sequence(train_df, sequence_length, sequence_cols)))\n",
        "           \n",
        "\n",
        "# generate sequences and convert to numpy array\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "    \n",
        "seq_array=np.reshape(seq_array, (len(seq_gen),sequence_length,len(sequence_cols)))\n",
        "print(seq_array.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "539Swsv3ATAr"
      },
      "source": [
        "# function to generate labels\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    # For one id I put all the labels in a single matrix.\n",
        "    # For example:\n",
        "    # [[1]\n",
        "    # [4]\n",
        "    # [1]\n",
        "    # [5]\n",
        "    # [9]\n",
        "    # ...\n",
        "    # [200]] \n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # I have to remove the first seq_length labels\n",
        "    # because for one id the first sequence of seq_length size have as target\n",
        "    # the last label (the previus ones are discarded).\n",
        "    # All the next id's sequences will have associated step by step one label as target. \n",
        "    return data_matrix[seq_length:num_elements, :]\n",
        "\n",
        "# generate labels\n",
        "label_gen = [gen_labels(train_df, sequence_length, ['rul'])]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "print(label_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_02o2qKLowK"
      },
      "source": [
        "model_path = \"/content/drive/MyDrive/model_predictive_maintanence/regression_model.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUci-UfKAu72"
      },
      "source": [
        "def r2_keras(y_true, y_pred):\n",
        "    \"\"\"Coefficient of Determination \n",
        "    \"\"\"\n",
        "    SS_res =  K.sum(K.square( y_true - y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "# Next, we build a deep network. \n",
        "# The first layer is an LSTM layer with 100 units followed by another LSTM layer with 50 units. \n",
        "# Dropout is also applied after each LSTM layer to control overfitting. \n",
        "# Final layer is a Dense output layer with single unit and sigmoid activation since this is a binary classification problem.\n",
        "# build the network\n",
        "\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(\n",
        "         input_shape=(sequence_length, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=nb_out, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae',r2_keras]) #'rmsprop'\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# fit the network\n",
        "history = model.fit(seq_array, label_array, epochs=500, batch_size=12, validation_split=False, verbose=1)\n",
        "model.save(model_path)\n",
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fzLNYEnDgO_"
      },
      "source": [
        "# summarize history for Accuracy\n",
        "fig_acc = plt.figure(figsize=(10, 10))\n",
        "plt.plot(history.history['r2_keras'])\n",
        "#plt.plot(history.history['val_r2_keras'])\n",
        "plt.title('model r^2')\n",
        "plt.ylabel('R^2')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "fig_acc.savefig(\"model_r2.png\")\n",
        "\n",
        "# summarize history for Mae\n",
        "fig_acc = plt.figure(figsize=(10, 10))\n",
        "plt.plot(history.history['mae'])\n",
        "#plt.plot(history.history['val_mae'])\n",
        "plt.title('model MAE')\n",
        "plt.ylabel('MAE')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "fig_acc.savefig(\"model_mae.png\")\n",
        "# summarize history for Loss\n",
        "fig_acc = plt.figure(figsize=(10, 10))\n",
        "plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "fig_acc.savefig(\"model_regression_loss.png\")\n",
        "\n",
        "# training metrics\n",
        "#scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=24)\n",
        "#print('\\nMAE: {}'.format(scores[1]))\n",
        "#print('\\nR^2: {}'.format(scores[2]))\n",
        "\n",
        "y_pred = model.predict(seq_array,verbose=1, batch_size=200)\n",
        "y_true = label_array\n",
        "\n",
        "test_set = pd.DataFrame(y_pred)\n",
        "test_set.to_csv('submit_train.csv', index = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIdEJVzd--yb"
      },
      "source": [
        "# pick the feature columns \n",
        "test_df = pd.concat([train_df,test_df],axis=0)\n",
        "sequence_cols=test_df.columns.difference([\"rul\",\"Time\"])\n",
        "\n",
        "# generator for the sequences\n",
        "#seq_gen=(list(gen_sequence(train_df[train_df.index==id], sequence_length, sequence_cols))  for id in train_df.index)\n",
        "seq_gen = list(list(gen_sequence(test_df, sequence_length, sequence_cols)))\n",
        "seq_gen1 = list(list(gen_sequence(train_df, sequence_length, sequence_cols)))           \n",
        "\n",
        "# generate sequences and convert to numpy array\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "seq_array1 = np.concatenate(list(seq_gen1)).astype(np.float32)    \n",
        "seq_array_test_last=np.reshape(seq_array, (len(seq_gen),sequence_length,len(sequence_cols)))\n",
        "seq_array_test_last1=np.reshape(seq_array1, (len(seq_gen1),sequence_length,len(sequence_cols)))\n",
        "print(seq_array_test_last.shape)\n",
        "print(seq_array_test_last1.shape)\n",
        "# generate labels\n",
        "label_gen = [gen_labels(test_df, sequence_length, ['rul'])]\n",
        "label_array_test_last = np.concatenate(label_gen).astype(np.float32)\n",
        "print(label_array_test_last.shape)\n",
        "# generate labels\n",
        "label_gen1 = [gen_labels(train_df, sequence_length, ['rul'])]\n",
        "label_array_test_last1 = np.concatenate(label_gen1).astype(np.float32)\n",
        "print(label_array_test_last1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi88dCgCKbgS"
      },
      "source": [
        " \n",
        "\n",
        "# if best iteration's model was saved then load and use it\n",
        "if os.path.isfile(model_path):\n",
        "    estimator = load_model(model_path,custom_objects={'r2_keras': r2_keras})\n",
        "\n",
        "    # test metrics\n",
        "    #scores_test = estimator.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n",
        "    #print('\\nMAE: {}'.format(scores_test[1]))\n",
        "    #print('\\nR^2: {}'.format(scores_test[2]))\n",
        "\n",
        "    y_pred_test = estimator.predict(seq_array_test_last)\n",
        "    y_true_test = label_array_test_last\n",
        "    y_pred_train = estimator.predict(seq_array_test_last1)\n",
        "    y_true_train = label_array_test_last1\n",
        "\n",
        "    test_set = pd.DataFrame(y_pred_test)\n",
        "    test_set.to_csv('submit_test.csv', index = None)\n",
        "\n",
        "    # Plot in blue color the predicted data and in green color the\n",
        "    # actual data to verify visually the accuracy of the model.\n",
        "    fig_verify = plt.figure(figsize=(10, 5))\n",
        "    plt.plot(y_pred_test, color=\"blue\")\n",
        "    plt.plot(y_true_train, color=\"green\")\n",
        "    plt.plot(y_pred_train,color=\"red\")\n",
        "    plt.title('prediction')\n",
        "    plt.ylabel('value')\n",
        "    plt.xlabel('row')\n",
        "    plt.legend(['test predicted', 'train actual data',\"train predicted\"], loc='upper left')\n",
        "    plt.show()\n",
        "    fig_verify.savefig(\"model_regression_verify.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj-SgX1gd6KX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}