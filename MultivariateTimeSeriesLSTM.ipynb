{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateTimeSeriesLSTM.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/MustafaBozkurt84/predictive-maintanance-LSTM/blob/master/MultivariateTimeSeriesLSTM.ipynb",
      "authorship_tag": "ABX9TyM8WBEgPSmkHQCTypFrIbYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafaBozkurt84/predictive-maintanance-LSTM/blob/master/MultivariateTimeSeriesLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFKcqM15ni_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682239aa-a124-4d90-dd6d-80a8d027cd3f"
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Setting seed for reproducibility\n",
        "np.random.seed(1234)  \n",
        "PYTHONHASHSEED = 0\n",
        "from matplotlib import pyplot\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "import pickle\n",
        "from numpy import concatenate\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "##################################\n",
        "# Data Ingestion\n",
        "##################################\n",
        "\n",
        "# read training data - It is the aircraft engine run-to-failure data.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2NDTcTU-csi",
        "outputId": "bcbf7791-9a7a-44f5-c557-e83c16ea71a9"
      },
      "source": [
        "df =pd.read_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /31_hidrolikmotoru_analiz.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eywWr6nI-eLL",
        "outputId": "5659b365-16f3-42d4-f024-aa6ce947cc45"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>time</th>\n",
              "      <th>partno</th>\n",
              "      <th>vibx</th>\n",
              "      <th>vibz</th>\n",
              "      <th>spm</th>\n",
              "      <th>temp</th>\n",
              "      <th>zacc</th>\n",
              "      <th>zfreq</th>\n",
              "      <th>xkurt</th>\n",
              "      <th>crestfactor</th>\n",
              "      <th>balancerbasinci</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sensorvib31</td>\n",
              "      <td>2020-01-01T00:00:01.70401Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.75</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2.94</td>\n",
              "      <td>3.6</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sensorvib31</td>\n",
              "      <td>2020-01-01T00:00:03.70467Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.75</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2.94</td>\n",
              "      <td>3.6</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sensorvib31</td>\n",
              "      <td>2020-01-01T00:00:05.70553Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.75</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2.97</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sensorvib31</td>\n",
              "      <td>2020-01-01T00:00:07.7093Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.75</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3.11</td>\n",
              "      <td>4.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sensorvib31</td>\n",
              "      <td>2020-01-01T00:00:09.70685Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.75</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3.11</td>\n",
              "      <td>4.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          name                        time  ... crestfactor  balancerbasinci\n",
              "0  sensorvib31  2020-01-01T00:00:01.70401Z  ...         3.6              NaN\n",
              "1  sensorvib31  2020-01-01T00:00:03.70467Z  ...         3.6              NaN\n",
              "2  sensorvib31  2020-01-01T00:00:05.70553Z  ...         4.2              NaN\n",
              "3  sensorvib31   2020-01-01T00:00:07.7093Z  ...         4.5              NaN\n",
              "4  sensorvib31  2020-01-01T00:00:09.70685Z  ...         4.5              NaN\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LnfA4j9IHD"
      },
      "source": [
        "\n",
        "df.drop([\"name\",\"partno\",\"balancerbasinci\",\"spm\",\"xkurt\"],axis=1,inplace=True)\n",
        "df.columns=['Time', 'vibx', 'vibz', 'temp', 'zacc', 'zfreq', 'crest']\n",
        "df[\"Time\"]= [str(i).replace(\"2020-02-02\",\"2/2/2020\").replace(\"2020-01-02\",\"2/1/2020\") for i in df[\"Time\"]]\n",
        "\n",
        "df['Time'] = pd.to_datetime(df['Time']) \n",
        "df['Time']=[str(i).split(\":\")[0] for i in df[\"Time\"]]\n",
        "df['Time'] = pd.to_datetime(df['Time'],format=\"%Y-%m-%d %H\") #%Y-%m-%d %H:%M:%S\n",
        "\n",
        "df=df.groupby(\"Time\").mean()\n",
        "df.reset_index(inplace=True)\n",
        "df.to_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /DataAnaliz.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxBegRHCm1kx"
      },
      "source": [
        "data=df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Gs4gyWm7gR"
      },
      "source": [
        "ariza_tarihleri=[\"2020-01-27 14:00:00\",\"2020-09-11 14:00:00\",\"2020-10-06 18:00:00\",\"2020-10-10 08:00:00\",\"2020-10-13 04:00:00\",\"2020-10-18 00:00:00\",\"2020-10-30 09:00:00\",\"2020-11-02 05:00:00\"]\n",
        "ariza_index = []\n",
        "for i in ariza_tarihleri:\n",
        "  ariza_index.append(df[df[\"Time\"]==i].index[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjqppidDowBF"
      },
      "source": [
        "ariza_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FueGgm2hpa6s"
      },
      "source": [
        "drop_index_list=[]\n",
        "for a in ariza_index:\n",
        "\n",
        "  for i in range(0,24*7):\n",
        "    drop_index_list.append(a+i)\n",
        "  for i in range(0,24*2):\n",
        "    drop_index_list.append(a-i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G12jLutqqlPO"
      },
      "source": [
        "df.drop(index=drop_index_list,axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNwOqpqrM9F"
      },
      "source": [
        "df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nl1aTCi6dC6"
      },
      "source": [
        "#df = pd.read_excel(\"/content/drive/MyDrive/Datasets/predictive maintance /AnalizDataPM.xlsx\",engine='openpyxl')\n",
        "#df[\"Time\"]= [str(i).replace(\"2020-02-02\",\"2/2/2020\").replace(\"2020-01-02\",\"2/1/2020\") for i in df[\"Time\"]]\n",
        "#df['Time'] = pd.to_datetime(df['Time']) \n",
        "#df['Time']=[str(i).split(\":\")[0] for i in df[\"Time\"]]\n",
        "#df['Time'] = pd.to_datetime(df['Time'],format=\"%Y-%m-%d %H\") #%Y-%m-%d %H:%M:%S\n",
        "#df=df.groupby(\"Time\").mean()\n",
        "#df.reset_index(inplace=True)\n",
        "#df.to_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /DataAnaliz.csv\")\n",
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaLSncQC6oWb"
      },
      "source": [
        "#fail_time =df[df[\"Time\"]==\"2020-01-27 14:00:00\"].index[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlPzyMkGNL-2"
      },
      "source": [
        " def feature_engineering(df):\n",
        "  df['Hour'] = df['Time'].apply(lambda time: time.hour)\n",
        "  df['Month'] = df['Time'].apply(lambda time: time.month)\n",
        "  df['Day of Week'] = df['Time'].apply(lambda time: time.dayofweek)\n",
        "  df['Year'] = df['Time'].apply(lambda t: t.year)\n",
        "  df=pd.get_dummies(df,columns=['Hour','Month','Day of Week','Year'],drop_first=True)\n",
        "  for col in df.columns[1:7]:\n",
        "    for i in range(1,4):\n",
        "      df['lag_'+str(i)+col] = df[col].shift(i)\n",
        "  for col in df.columns[1:7]:\n",
        "    df[col+'expanding_mean'] = df[col].expanding(24).mean()\n",
        "    df[col+'expanding_std'] = df[col].expanding(24).std()\n",
        "  df.dropna(axis=0,inplace=True)\n",
        "  return df\n",
        "data =feature_engineering(data)\n",
        "data=data.iloc[5000:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5WpIzkj6rDO"
      },
      "source": [
        "df['Hour'] = df['Time'].apply(lambda time: time.hour)\n",
        "df['Month'] = df['Time'].apply(lambda time: time.month)\n",
        "df['Day of Week'] = df['Time'].apply(lambda time: time.dayofweek)\n",
        "df['Year'] = df['Time'].apply(lambda t: t.year)\n",
        "df=pd.get_dummies(df,columns=['Hour','Month','Day of Week','Year'],drop_first=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khY7pdnGj-DH"
      },
      "source": [
        "for col in df.columns[1:7]:\n",
        "  for i in range(1,4):\n",
        "      df['lag_'+str(i)+col] = df[col].shift(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tknGJB1lNf"
      },
      "source": [
        "for col in df.columns[1:7]:\n",
        "  df[col+'expanding_mean'] = df[col].expanding(24).mean()\n",
        "  df[col+'expanding_std'] = df[col].expanding(24).std()\n",
        "df.dropna(axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1skod7oB66CX"
      },
      "source": [
        "values = df.iloc[:,1:].values\n",
        "# specify columns to plot\n",
        "groups = [0,1, 2, 3, 4,5,6]\n",
        "i = 1\n",
        "# plot each column\n",
        "pyplot.figure(figsize=(20, 11), dpi=80)\n",
        "for group in groups:\n",
        "\tpyplot.subplot(len(groups), 1, i)\n",
        "\tpyplot.plot(values[:, group])\n",
        "\tpyplot.title(df.columns[group], y=0.5, loc='right')\n",
        "\ti += 1\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCq07m_M7QIe"
      },
      "source": [
        "# prepare data for lstm\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        " \n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1qg9lXAHEjw"
      },
      "source": [
        "def pickle_all(key,value):\n",
        "         pickle_out = open(key, \"wb\")\n",
        "         pickle.dump(value, pickle_out)\n",
        "         pickle_out.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeNJSN9A8XHv"
      },
      "source": [
        " def multivariae_lstm(col_num):\n",
        "    print(\"*\"*30+df.columns[col_num+1]+\"*\"*30)\n",
        "    values = df.iloc[:4700,1:].values\n",
        "    # integer encode direction\n",
        "    #encoder = LabelEncoder()\n",
        "    #values[:,4] = encoder.fit_transform(values[:,4])\n",
        "    # ensure all data is float\n",
        "    values = values.astype('float32')\n",
        "    # normalize features\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled = scaler.fit_transform(values)\n",
        "    pickle_all(f\"/content/drive/MyDrive/model_predictive_maintanence/{df.columns[col_num+1]}_scaler_lstm_multivariate.pkl\",scaler)\n",
        "    #scaled=values\n",
        "    # specify the number of lag hours\n",
        "    test=data.iloc[:,1:].values\n",
        "    test = test.astype('float32')\n",
        "    scaled_test=scaler.transform(test)\n",
        "    n_hours = 10\n",
        "    n_features = df.iloc[:,1:].shape[1]\n",
        "    # frame as supervised learning\n",
        "    reframed = series_to_supervised(scaled, n_hours, 1)\n",
        "    test_reframed=series_to_supervised(scaled_test, n_hours, 1)\n",
        "    #print(reframed.shape)\n",
        "    \n",
        "    # split into train and test sets\n",
        "    values = reframed.values\n",
        "    n_train_hours = 7000\n",
        "    #train = values[:n_train_hours, :]\n",
        "    train = values\n",
        "\n",
        "    test = test_reframed.values\n",
        "    # split into input and outputs\n",
        "    n_obs = n_hours * n_features\n",
        "    train_X, train_y = train[:, :n_obs], train[:, col_num]\n",
        "    test_X, test_y = test[:, :n_obs], test[:, col_num]\n",
        "    #print(train_X.shape, len(train_X), train_y.shape)\n",
        "    # reshape input to be 3D [samples, timesteps, features]\n",
        "    train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
        "    test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
        "    #print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
        "    # design network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mae', optimizer='adam')\n",
        "    # fit network\n",
        "    history = model.fit(train_X, train_y, epochs=100, batch_size=10, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
        "    # make a prediction\n",
        "    model.save(f\"/content/drive/MyDrive/model_predictive_maintanence/{df.columns[col_num+1]}multivariateLSTM_model.h5\")\n",
        "    yhat = model.predict(test_X)\n",
        "    test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
        "    # plot history\n",
        "    \n",
        "    pyplot.plot(history.history['loss'], label='train')\n",
        "    pyplot.plot(history.history['val_loss'], label='test')\n",
        "    pyplot.legend()\n",
        "    pyplot.show()\n",
        "        \n",
        "    # invert scaling for forecast\n",
        "\n",
        "    inv_yhat1 = np.repeat(yhat, df.shape[1]-1, axis=-1)\n",
        "    inv_yhat1 = scaler.inverse_transform(inv_yhat1)\n",
        "    inv_yhat1 = inv_yhat1[:,0]\n",
        "    # invert scaling for actual\n",
        "    test_y = test_y.reshape((len(test_y), 1))\n",
        "\n",
        "    inv_y = np.repeat(test_y, df.shape[1]-1, axis=-1)\n",
        "    inv_y = scaler.inverse_transform(inv_y)\n",
        "    inv_y = inv_y[:,0]\n",
        "    # calculate RMSE\n",
        "    \n",
        "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat1))\n",
        "    print('Test RMSE: %.3f' % rmse)\n",
        "    ariza_tarihleri_plot= []\n",
        "    for i in [str(a) for a in data[\"Time\"]]:\n",
        "      if i not in [str(b) for b in ariza_tarihleri]:\n",
        "        ariza_tarihleri_plot.append(data[df.columns[col_num+1]].min())\n",
        "      else:\n",
        "        ariza_tarihleri_plot.append(data[df.columns[col_num+1]].max())\n",
        "    ariza_tarihleri_plot=ariza_tarihleri_plot[5000:]\n",
        "    pyplot.figure(figsize=(12, 8), dpi=80)\n",
        "    pyplot.plot(inv_y,label=df.columns[col_num+1])\n",
        "    pyplot.plot(inv_yhat1,label=df.columns[col_num+1]+\"_predicted\")\n",
        "    pyplot.plot(ariza_tarihleri_plot,label = \"ariza_tarihleri\")\n",
        "    pyplot.title(df.columns[col_num+1]+\" multivariate LSTM\")\n",
        "    pyplot.legend()\n",
        "    pyplot.show()\n",
        "    \n",
        "\n",
        "    return inv_yhat1,inv_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YKgpILKPNdK"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHCm8i6G9dy0"
      },
      "source": [
        "for i in range(0,6):\n",
        "    inv_yhat1,inv_y=multivariae_lstm(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTgmrrgAquKh"
      },
      "source": [
        "for i in [65,66,67,68,69,70,71,72,73,74,75,76,77]:\n",
        "    inv_yhat1,inv_y=multivariae_lstm(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amGb-4CMRYpW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}