{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Arima1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafaBozkurt84/predictive-maintanance-LSTM/blob/master/Arima1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s9htrBN83WK",
        "outputId": "eb9b1123-0c80-4ae3-ea57-e7393ed65b35"
      },
      "source": [
        "!pip install statsmodels --upgrade"
      ],
      "id": "7s9htrBN83WK",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: statsmodels in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sensitive-lighting"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle"
      ],
      "id": "sensitive-lighting",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKsJugLDxOnH",
        "outputId": "85304e37-d0bf-4dc2-cb93-43b8985ca0bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "gKsJugLDxOnH",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxYF2EiqAXHw"
      },
      "source": [
        "df =pd.read_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /31_hidrolikmotoru_analiz.csv\")"
      ],
      "id": "yxYF2EiqAXHw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9cBVRI6Avl7"
      },
      "source": [
        "df.head()"
      ],
      "id": "D9cBVRI6Avl7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWd0YTVQBAv_"
      },
      "source": [
        "df.drop([\"name\",\"partno\",\"balancerbasinci\",\"spm\",\"xkurt\"],axis=1,inplace=True)"
      ],
      "id": "qWd0YTVQBAv_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha23-5QlBZwA"
      },
      "source": [
        "df.columns=['Time', 'vibx', 'vibz', 'temp', 'zacc', 'zfreq', 'crest']"
      ],
      "id": "Ha23-5QlBZwA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4SHzGUdeycO"
      },
      "source": [
        "#df = pd.read_excel(\"/content/drive/MyDrive/Datasets/predictive maintance /AnalizDataPM.xlsx\",engine='openpyxl')\n",
        "df[\"Time\"]= [str(i).replace(\"2020-02-02\",\"2/2/2020\").replace(\"2020-01-02\",\"2/1/2020\") for i in df[\"Time\"]]\n"
      ],
      "id": "z4SHzGUdeycO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf55CVmr5_wj"
      },
      "source": [
        "df['Time'] = pd.to_datetime(df['Time']) \n",
        "df['Time']=[str(i).split(\":\")[0] for i in df[\"Time\"]]"
      ],
      "id": "lf55CVmr5_wj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZc3ldG635jX"
      },
      "source": [
        "df['Time'] = pd.to_datetime(df['Time'],format=\"%Y-%m-%d %H\") #%Y-%m-%d %H:%M:%S"
      ],
      "id": "HZc3ldG635jX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9agMMLeK4CsG"
      },
      "source": [
        "df=df.groupby(\"Time\").mean()\n",
        "df.reset_index(inplace=True)\n",
        "df.to_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /DataAnaliz.csv\")\n",
        "df.head()"
      ],
      "id": "9agMMLeK4CsG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2kivntoDDOn"
      },
      "source": [
        "df.shape"
      ],
      "id": "d2kivntoDDOn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vewgsfs77N29"
      },
      "source": [
        "for col in df.columns[1:]:\n",
        "  df[col]=[round(i,2)for i in df[col]]"
      ],
      "id": "Vewgsfs77N29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stQvYvjn9O3l"
      },
      "source": [
        "df1=df.copy()"
      ],
      "id": "stQvYvjn9O3l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE2Y2_zY9t6c"
      },
      "source": [
        "df1['Time'] = [str(i).split()[0] for i in df1['Time']]\n",
        "df1['Time'] = pd.to_datetime(df1['Time'],format=\"%Y-%m-%d\")\n",
        "df1.set_index(\"Time\",inplace=True)\n",
        "\n"
      ],
      "id": "mE2Y2_zY9t6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQXScKrb-n-u"
      },
      "source": [
        "df1=df1.groupby(\"Time\").mean()\n",
        "df1.iloc[:,1].plot()"
      ],
      "id": "OQXScKrb-n-u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf6UMpYEyh8Z"
      },
      "source": [
        "#df=pd.read_csv(\"/content/drive/MyDrive/Datasets/predictive maintance /DataAnaliz.csv\",parse_date=True)\n",
        "#df=df.iloc[:,1:]"
      ],
      "id": "jf6UMpYEyh8Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c192ad1"
      },
      "source": [
        "\n",
        "# ARIMA and Seasonal ARIMA\n",
        "\n",
        "\n",
        "## Autoregressive Integrated Moving Averages\n",
        "\n",
        "The general process for ARIMA models is the following:\n",
        "* Visualize the Time Series Data\n",
        "* Make the time series data stationary\n",
        "* Plot the Correlation and AutoCorrelation Charts\n",
        "* Construct the ARIMA Model or Seasonal ARIMA based on the data\n",
        "* Use the model to make predictions\n",
        "\n",
        "Let's go through these steps!"
      ],
      "id": "4c192ad1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12e32dfc"
      },
      "source": [
        "df_vibx = df.loc[:,[\"Time\",\"vibx\"]]\n",
        "df_vibz = df.loc[:,[\"Time\",\"vibz\"]]\n",
        "df_temp = df.loc[:,[\"Time\",\"temp\"]]\n",
        "df_zacc = df.loc[:,[\"Time\",\"zacc\"]]\n",
        "df_crest = df.loc[:,[\"Time\",\"crest\"]]\n",
        "df_zfreq = df.loc[:,[\"Time\",\"zfreq\"]]"
      ],
      "id": "12e32dfc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f412e30"
      },
      "source": [
        "dataframes=[df_vibx,df_vibz,df_temp,df_zacc,df_crest,df_zfreq]"
      ],
      "id": "2f412e30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b44f7da9"
      },
      "source": [
        "for data in dataframes:\n",
        "    data.set_index(\"Time\",inplace=True)\n",
        "    data.index = pd.DatetimeIndex(data.index)\n",
        "    data.plot(figsize=(15, 6))\n",
        "    plt.title(data.columns[0])"
      ],
      "id": "b44f7da9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvDzX8xm9-ac"
      },
      "source": [
        "df.describe()"
      ],
      "id": "OvDzX8xm9-ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cd83b0e"
      },
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "#Ho: It is non stationary\n",
        "#H1: It is stationary\n",
        "\n",
        "def adfuller_test(col,colname):\n",
        "    print(\"-\"*20 + f\"{colname}\"+ 20*\"-\")\n",
        "    result=adfuller(col)\n",
        "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
        "    for value,label in zip(result,labels):\n",
        "        print(label+' : '+str(value) )\n",
        "    \n",
        "    if result[1] <= 0.05:\n",
        "        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n",
        "    else:\n",
        "        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")\n",
        "    print(20*\"*\")\n"
      ],
      "id": "0cd83b0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f6b529e"
      },
      "source": [
        "for col in df.columns[1:]:\n",
        "  adfuller_test(df.loc[:,col],col)"
      ],
      "id": "9f6b529e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa5357be"
      },
      "source": [
        "from pandas.plotting import autocorrelation_plot\n",
        "for col in df.columns[1:]:\n",
        "  autocorrelation_plot(df[col])\n",
        "  plt.title(f\"{col}\")\n",
        "  plt.show()"
      ],
      "id": "fa5357be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZtNdRJrISTu"
      },
      "source": [
        "### Final Thoughts on Autocorrelation and Partial Autocorrelation\n",
        "\n",
        "* Identification of an AR model is often best done with the PACF.\n",
        "    * For an AR model, the theoretical PACF “shuts off” past the order of the model.  The phrase “shuts off” means that in theory the partial autocorrelations are equal to 0 beyond that point.  Put another way, the number of non-zero partial autocorrelations gives the order of the AR model.  By the “order of the model” we mean the most extreme lag of x that is used as a predictor.\n",
        "    \n",
        "    \n",
        "* Identification of an MA model is often best done with the ACF rather than the PACF.\n",
        "    * For an MA model, the theoretical PACF does not shut off, but instead tapers toward 0 in some manner.  A clearer pattern for an MA model is in the ACF.  The ACF will have non-zero autocorrelations only at lags involved in the model.\n",
        "    \n",
        "    p,d,q\n",
        "    p AR model lags\n",
        "    d differencing\n",
        "    q MA lags"
      ],
      "id": "VZtNdRJrISTu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BczRdWO-faE"
      },
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
        "def Autocorrelation_plot(df,col):\n",
        "    fig = plt.figure(figsize=(12,8))\n",
        "    ax1 = fig.add_subplot(211)\n",
        "    fig = plot_acf(df[col],lags=40,ax=ax1)\n",
        "    ax2 = fig.add_subplot(212)\n",
        "    ax1.set_title(f\" Autocorrelation ({col}) \")\n",
        "    fig = plot_pacf(df[col],lags=40,ax=ax2)\n",
        "    ax2.set_title(f\" Partial Autocorrelation ({col})\")\n",
        "    "
      ],
      "id": "2BczRdWO-faE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJoXxa40I9wW"
      },
      "source": [
        "for col in df.columns[1:]:\n",
        "  Autocorrelation_plot(df,col)"
      ],
      "id": "mJoXxa40I9wW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dml7iorFo_Nu"
      },
      "source": [
        "!pip install pmdarima"
      ],
      "id": "dml7iorFo_Nu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MU1-DND9ab-"
      },
      "source": [
        "\n",
        "from pmdarima import auto_arima\n"
      ],
      "id": "4MU1-DND9ab-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf6mqqoFz3FP"
      },
      "source": [
        "\n",
        "for i in df1.columns:\n",
        "    print(50*\"*\")\n",
        "    print(i)\n",
        "    stepwise_fit = auto_arima(df1[i], start_p=1, start_q=1,\n",
        "                           max_p=3, max_q=3, m=7,\n",
        "                           start_P=0, seasonal=True,\n",
        "                           d=0, D=0, trace=True,\n",
        "                           error_action='ignore',  \n",
        "                           suppress_warnings=True, \n",
        "                           stepwise=True)"
      ],
      "id": "Sf6mqqoFz3FP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urzz-cn5zQnp"
      },
      "source": [
        " def pickle_all(key,value):\n",
        "         pickle_out = open(\"/content/drive/MyDrive/model_predictive_maintanence/\"+key+\"_arima.pkl\", \"wb\")\n",
        "         pickle.dump(value, pickle_out)\n",
        "         pickle_out.close()"
      ],
      "id": "Urzz-cn5zQnp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI0-gqZKLNBl"
      },
      "source": [
        "# For non-seasonal data\n",
        "#p=1, d=1, q=0 or 1\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARMA',\n",
        "                        FutureWarning)\n",
        "import statsmodels.api as sm"
      ],
      "id": "bI0-gqZKLNBl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1xUmXYMNLnu"
      },
      "source": [
        "def arima_model(df,col,date,date1,p,d,q,p1,d1,q1,m):\n",
        "    #df.index = pd.DatetimeIndex(df.index)\n",
        "    df[\"arıza\"]=df[col]\n",
        "    df[\"arıza\"]=np.where((df[\"Time\"]>\"2020-01-27 14:00:00\")&(df[\"Time\"] <\"2020-01-27 16:00:00\"),df[col].max(),df[col].min())\n",
        "    #model=ARIMA(df[df.index < date][col],order=(p,d,q))\n",
        "    model=sm.tsa.statespace.SARIMAX(df[(df[\"Time\"]>date)&(df[\"Time\"]<date1)][[col]],order=(p, d, q),seasonal_order=(p1,d1,q1,m))\n",
        "    \n",
        "    model_fit=model.fit()\n",
        "    pickle_all(col,model_fit)\n",
        "    \n",
        "    print(model_fit.summary())\n",
        "    print(df.head())\n",
        "    df2=df[df.index<1200][[col]]\n",
        "    df2['forecast_'+col]=model_fit.predict(start=df2.index[0],end=df2.index[-1])\n",
        "    df2[\"arıza\"]=df[\"arıza\"]\n",
        "    df2[[col,'forecast_'+col,\"arıza\"]].iloc[:1200].plot(figsize=(12,8))\n",
        "    df2[\"Dif\"] = ((df2[col]-df2['forecast_'+col])/df2[col])\n",
        "    return df2"
      ],
      "id": "z1xUmXYMNLnu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyPploF4MHMA"
      },
      "source": [
        "df2=arima_model(df,\"vibx\",\"2020-02-02 17:00:00\",\"2020-02-21 14:00:00\",2,0,2,1,0,1,7*24) #(2,0,2)(1,0,1)"
      ],
      "id": "eyPploF4MHMA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az6AfYOfz-Qq"
      },
      "source": [
        "df2"
      ],
      "id": "az6AfYOfz-Qq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsarDZr8_ihN"
      },
      "source": [
        "arima_model(df,\"vibz\",\"2020-01-28 00:00:00\",\"2020-02-21 14:00:00\",1,0,0,1,0,1,24*7) #(1,0,0)(1,0,1) "
      ],
      "id": "OsarDZr8_ihN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdv8ERYUzk_5"
      },
      "source": [
        "arima_model(df,\"temp\",\"2020-01-28 00:00:00\",\"2020-02-21 14:00:00\",1,0,0,1,0,0,24*7) #(3,0,0)(2,0,0)"
      ],
      "id": "zdv8ERYUzk_5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1wvaz_V0Adx"
      },
      "source": [
        "arima_model(df,\"zacc\",\"2020-01-28 00:00:00\",\"2020-02-21 14:00:00\",1,0,0,1,0,0,24*7) #(3,0,0)(2,0,0)"
      ],
      "id": "n1wvaz_V0Adx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBxcsIfk1Jou"
      },
      "source": [
        "arima_model(df,\"crest\",\"2020-01-28 00:00:00\",\"2020-02-21 14:00:00\",1,0,0,1,0,0,7*24) #(1,0,0)(0,0,0)"
      ],
      "id": "UBxcsIfk1Jou",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL4o4uZb1S5P"
      },
      "source": [
        "arima_model(df,\"zfreq\",\"2020-01-28 00:00:00\",\"2020-02-21 14:00:00\",1,0,1,1,0,1,7*24) #(3,0,0)(1,0,0)"
      ],
      "id": "EL4o4uZb1S5P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZZbomAdtftV"
      },
      "source": [
        "for i in df.columns:\n",
        "  print(f\"{i} sensoru  {df[df[i]==df[i].max()].index[0]} de en yuksek degerı olan {df[i].max()} degerını kaydetmis \")\n"
      ],
      "id": "sZZbomAdtftV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdGdmAUi_orZ"
      },
      "source": [
        "\"\"\"vibx sensoru  2020-01-27 04:00:00 de en yuksek degerı olan 2.3257780256553273 degerını kaydetmis \n",
        "vibz sensoru  2020-01-27 05:00:00 de en yuksek degerı olan 3.027547281323874 degerını kaydetmis \n",
        "temp sensoru  2020-01-27 05:00:00 de en yuksek degerı olan 35.27760047281316 degerını kaydetmis \n",
        "zacc sensoru  2020-01-27 03:00:00 de en yuksek degerı olan 0.7172621035058485 degerını kaydetmis \n",
        "crest sensoru  2020-01-19 13:00:00 de en yuksek degerı olan 10.865886603668711 degerını kaydetmis \n",
        "zfreq sensoru  2020-01-27 03:00:00 de en yuksek degerı olan 0.17328324986088234 degerını kaydetmis \"\"\""
      ],
      "id": "DdGdmAUi_orZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJNOsW9khR5"
      },
      "source": [
        ""
      ],
      "id": "BkJNOsW9khR5",
      "execution_count": null,
      "outputs": []
    }
  ]
}